{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9edbd00b",
      "metadata": {
        "id": "9edbd00b"
      },
      "source": [
        "\n",
        "# SiameseBERT Training Notebook\n",
        "\n",
        "This notebook trains a Siamese BERT model using cosine embedding loss on a dataset\n",
        "of tokenized issue pairs. It is the notebook version of your original Python script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YgFBIcFbQ2hb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgFBIcFbQ2hb",
        "outputId": "df24be4a-9266-4d52-a951-12b96ceb66a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Current working directory: /content/drive/.shortcut-targets-by-id/1AX1-1KC_cgwCqo-A4ecfxoHQWVfm-yV1/CS588\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Mount Google Drive and set CS588 as the main directory (for Colab)\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Adjust this path if your CS588 folder is elsewhere in Drive\n",
        "BASE_DIR = '/content/drive/MyDrive/CS588'\n",
        "os.chdir(BASE_DIR)\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# this cell for baselines."
      ],
      "metadata": {
        "id": "00WA0IKcUEcl"
      },
      "id": "00WA0IKcUEcl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oUfJmAOfnjaa",
      "metadata": {
        "id": "oUfJmAOfnjaa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "from dataset import TokenizedDataset\n",
        "from sbert import SiameseBERT\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "from dataset import TokenizedDataset\n",
        "from sbert import SiameseBERT\n",
        "\n",
        "\n",
        "\n",
        "def train(\n",
        "    csv_path: str,\n",
        "    model_name: str = \"bert-base-uncased\",\n",
        "    batch_size: int = 1024,\n",
        "    epochs: int = 3,\n",
        "    lr: float = 2e-5,\n",
        "    dataset_name: str = \"thunderbird\",\n",
        "\n",
        "):\n",
        "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 1. Load Dataset\n",
        "    print(f\"Loading dataset from {csv_path}...\")\n",
        "    dataset = TokenizedDataset(csv_path)\n",
        "    print(f\"Dataset size: {len(dataset)}\")\n",
        "\n",
        "    # Split into Train (60%), Validation (20%), Test (20%)\n",
        "    total_len = len(dataset)\n",
        "    train_len = int(0.6 * total_len)\n",
        "    val_len = int(0.2 * total_len)\n",
        "    test_len = total_len - train_len - val_len\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
        "\n",
        "    print(f\"Train size: {len(train_dataset)} | Validation size: {len(val_dataset)} | Test size: {len(test_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)} | Test batches: {len(test_loader)}\")\n",
        "\n",
        "    # 2. Initialize Model\n",
        "    print(f\"Initializing SiameseBERT with {model_name}...\")\n",
        "    model = SiameseBERT(model_name=model_name)\n",
        "    model.to(device)\n",
        "\n",
        "    # 3. Setup Training\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.CosineEmbeddingLoss(margin=0.5)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_losses = []\n",
        "    epoch_accuracies = []\n",
        "    epoch_f1s = []\n",
        "    epoch_recalls = []\n",
        "    epoch_precisions = []\n",
        "\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    val_f1s = []\n",
        "    val_recalls = []\n",
        "    val_precisions = []\n",
        "\n",
        "    # === store per-iteration loss here ===\n",
        "    step_losses = []             # list of (global_step, loss_value)\n",
        "    global_step = 0\n",
        "\n",
        "    embedding_dict = {}\n",
        "\n",
        "    # 0. Create save directory with date (and time) ONCE\n",
        "    run_timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # e.g. 2025-12-09_13-45-02\n",
        "    save_root = os.path.join(\"checkpoints\", dataset_name)          # or any base folder you want\n",
        "    save_dir = os.path.join(save_root, run_timestamp)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    print(f\"Checkpoints and figures will be saved under: {save_dir}\")\n",
        "\n",
        "    # optional: CSV log for each iteration\n",
        "    iter_log_path = \"train_step_losses.csv\"   # stays in CWD unless you also want this in save_dir\n",
        "    last_all_labels = None\n",
        "    last_all_preds = None\n",
        "\n",
        "    with open(iter_log_path, \"w\", newline=\"\") as f_log:\n",
        "        writer = csv.writer(f_log)\n",
        "        writer.writerow([\"global_step\", \"epoch\", \"batch_idx\", \"loss\"])\n",
        "\n",
        "        threshold = 0.5  # for accuracy from cosine similarity\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "            total_loss = 0.0\n",
        "            total_correct = 0\n",
        "            total_examples = 0\n",
        "\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "\n",
        "            # Training Loop\n",
        "            model.train()\n",
        "            progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
        "\n",
        "            for batch_idx, batch in progress_bar:\n",
        "                global_step += 1\n",
        "\n",
        "                # Move batch to device\n",
        "                input_ids1 = batch['input_ids1'].to(device)\n",
        "                attention_mask1 = batch['attention_mask1'].to(device)\n",
        "                input_ids2 = batch['input_ids2'].to(device)\n",
        "                attention_mask2 = batch['attention_mask2'].to(device)\n",
        "                issue_id1 = batch[\"issue_id1\"]\n",
        "                issue_id2 = batch[\"issue_id2\"]\n",
        "\n",
        "                labels01 = batch['label'].to(device).float()  # {0,1}\n",
        "\n",
        "                # For CosineEmbeddingLoss: targets in {1, -1}\n",
        "                targets = 2 * labels01 - 1.0  # 0 -> -1, 1 -> +1\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                embeddings1, embeddings2 = model(\n",
        "                    input_ids1, attention_mask1,\n",
        "                    input_ids2, attention_mask2\n",
        "                )\n",
        "\n",
        "                if issue_id1 is not None and issue_id2 is not None:\n",
        "                    # Optimize: Batch processing for CLS tokens\n",
        "                    # Note: This runs BERT a second time, but in batch mode (faster than loop)\n",
        "                    # Ideally, modify model.forward to return CLS tokens to avoid re-computation\n",
        "                    cls1 = model.create_embedding(input_ids1, attention_mask1)\n",
        "                    cls2 = model.create_embedding(input_ids2, attention_mask2)\n",
        "\n",
        "                    for i in range(len(issue_id1)):\n",
        "                        embedding_dict[issue_id1[i].item()] = cls1[i].detach().cpu()\n",
        "                        embedding_dict[issue_id2[i].item()] = cls2[i].detach().cpu()\n",
        "\n",
        "                loss = criterion(embeddings1, embeddings2, targets)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                loss_value = loss.item()\n",
        "                total_loss += loss_value\n",
        "\n",
        "                # ---- Accuracy computation ----\n",
        "                with torch.no_grad():\n",
        "                    cos_sim = F.cosine_similarity(embeddings1, embeddings2)  # [B]\n",
        "                    preds = (cos_sim > threshold).float()                   # {0,1}\n",
        "                    correct = (preds == labels01).sum().item()\n",
        "                    total_correct += correct\n",
        "                    total_examples += labels01.numel()\n",
        "                    batch_acc = correct / labels01.numel()\n",
        "\n",
        "                    preds_np = preds.cpu().numpy()\n",
        "                    labels_np = labels01.cpu().numpy()\n",
        "\n",
        "                    all_preds.extend(preds_np)\n",
        "                    all_labels.extend(labels_np)\n",
        "\n",
        "                    batch_f1 = f1_score(labels_np, preds_np, zero_division=0)\n",
        "\n",
        "                # log per-iteration loss\n",
        "                step_losses.append((global_step, loss_value))\n",
        "                writer.writerow([global_step, epoch + 1, batch_idx, loss_value])\n",
        "\n",
        "                progress_bar.set_postfix({\n",
        "                    'loss': f\"{loss_value:.4f}\",\n",
        "                    'acc': f\"{batch_acc:.3f}\",\n",
        "                    'f1': f\"{batch_f1:.3f}\"\n",
        "                })\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            avg_acc = total_correct / total_examples\n",
        "\n",
        "            epoch_f1 = f1_score(all_labels, all_preds)\n",
        "            epoch_recall = recall_score(all_labels, all_preds)\n",
        "            epoch_precision = precision_score(all_labels, all_preds)\n",
        "\n",
        "            print(f\"Train | Loss: {avg_loss:.4f} | Acc: {avg_acc:.4f} | F1: {epoch_f1:.4f} | Rec: {epoch_recall:.4f} | Prec: {epoch_precision:.4f}\")\n",
        "\n",
        "            epoch_losses.append(avg_loss)\n",
        "            epoch_accuracies.append(avg_acc)\n",
        "            epoch_f1s.append(epoch_f1)\n",
        "            epoch_recalls.append(epoch_recall)\n",
        "            epoch_precisions.append(epoch_precision)\n",
        "\n",
        "            # Validation Loop\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_all_sims = []\n",
        "            val_all_labels = []\n",
        "\n",
        "            # Open a file to log sample comparisons for this epoch\n",
        "            sample_log_path = os.path.join(save_dir, f\"val_samples_epoch_{epoch+1}.txt\")\n",
        "            with open(sample_log_path, \"w\") as f_sample:\n",
        "                f_sample.write(\"Issue1_ID\\tIssue2_ID\\tLabel\\tSimilarity\\n\")\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for batch in tqdm(val_loader, desc=\"Validation\"):\n",
        "                        input_ids1 = batch['input_ids1'].to(device)\n",
        "                        attention_mask1 = batch['attention_mask1'].to(device)\n",
        "                        input_ids2 = batch['input_ids2'].to(device)\n",
        "                        attention_mask2 = batch['attention_mask2'].to(device)\n",
        "                        labels01 = batch['label'].to(device).float()\n",
        "                        targets = 2 * labels01 - 1.0\n",
        "\n",
        "                        # Get issue IDs for logging\n",
        "                        val_issue_id1 = batch.get(\"issue_id1\")\n",
        "                        val_issue_id2 = batch.get(\"issue_id2\")\n",
        "\n",
        "                        embeddings1, embeddings2 = model(input_ids1, attention_mask1, input_ids2, attention_mask2)\n",
        "                        loss = criterion(embeddings1, embeddings2, targets)\n",
        "                        val_loss += loss.item()\n",
        "\n",
        "\n",
        "                        if val_issue_id1 is not None and val_issue_id2 is not None:\n",
        "                        # Optimize: Batch processing for CLS tokens\n",
        "                                # Note: This runs BERT a second time, but in batch mode (faster than loop)\n",
        "                                # Ideally, modify model.forward to return CLS tokens to avoid re-computation\n",
        "                                cls1 = model.create_embedding(input_ids1, attention_mask1)\n",
        "                                cls2 = model.create_embedding(input_ids2, attention_mask2)\n",
        "\n",
        "                                for i in range(len(val_issue_id1)):\n",
        "                                    embedding_dict[val_issue_id1[i].item()] = cls1[i].detach().cpu()\n",
        "                                    embedding_dict[val_issue_id2[i].item()] = cls2[i].detach().cpu()\n",
        "\n",
        "\n",
        "                        cos_sim = F.cosine_similarity(embeddings1, embeddings2)\n",
        "\n",
        "                        val_all_sims.extend(cos_sim.cpu().numpy())\n",
        "                        val_all_labels.extend(labels01.cpu().numpy())\n",
        "\n",
        "                        # Log samples\n",
        "                        if val_issue_id1 is not None and val_issue_id2 is not None:\n",
        "                            sims_np = cos_sim.cpu().numpy()\n",
        "                            labels_np = labels01.cpu().numpy()\n",
        "                            ids1_np = val_issue_id1.numpy() if isinstance(val_issue_id1, torch.Tensor) else val_issue_id1\n",
        "                            ids2_np = val_issue_id2.numpy() if isinstance(val_issue_id2, torch.Tensor) else val_issue_id2\n",
        "\n",
        "                            for i in range(len(sims_np)):\n",
        "                                f_sample.write(f\"{ids1_np[i]}\\t{ids2_np[i]}\\t{labels_np[i]}\\t{sims_np[i]:.4f}\\n\")\n",
        "\n",
        "            print(f\"Validation samples logged to {sample_log_path}\")\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "            # Adaptive Thresholding\n",
        "            thresholds = np.arange(0.3, 0.95, 0.05)\n",
        "            best_f1 = -1.0\n",
        "            best_thresh = 0.5\n",
        "            best_metrics = {}\n",
        "\n",
        "            val_sims_np = np.array(val_all_sims)\n",
        "            val_labels_np = np.array(val_all_labels)\n",
        "\n",
        "            for th in thresholds:\n",
        "                preds = (val_sims_np >= th).astype(int)\n",
        "                f1 = f1_score(val_labels_np, preds, zero_division=0)\n",
        "\n",
        "                if f1 > best_f1:\n",
        "                    best_f1 = f1\n",
        "                    best_thresh = th\n",
        "                    best_metrics = {\n",
        "                        'acc': (preds == val_labels_np).mean(),\n",
        "                        'rec': recall_score(val_labels_np, preds, zero_division=0),\n",
        "                        'prec': precision_score(val_labels_np, preds, zero_division=0)\n",
        "                    }\n",
        "\n",
        "            print(f\"Val   | Best Thresh: {best_thresh:.2f} | Loss: {avg_val_loss:.4f} | Acc: {best_metrics['acc']:.4f} | F1: {best_f1:.4f} | Rec: {best_metrics['rec']:.4f} | Prec: {best_metrics['prec']:.4f}\")\n",
        "\n",
        "            val_losses.append(avg_val_loss)\n",
        "            val_accuracies.append(best_metrics['acc'])\n",
        "            val_f1s.append(best_f1)\n",
        "            val_recalls.append(best_metrics['rec'])\n",
        "            val_precisions.append(best_metrics['prec'])\n",
        "\n",
        "            # keep last epoch's preds/labels (using best threshold)\n",
        "            last_all_labels = np.array(all_labels)\n",
        "            last_all_preds = np.array(all_preds)\n",
        "\n",
        "            # Save checkpoint\n",
        "            ckpt_path = os.path.join(save_dir, f\"sbert_epoch_{epoch + 1}.pth\")\n",
        "            torch.save(model.state_dict(), ckpt_path)\n",
        "            print(f\"Model saved to {ckpt_path}\")\n",
        "\n",
        "    print(f\"Per-iteration losses saved to {iter_log_path}\")\n",
        "\n",
        "    # === Confusion matrix for LAST epoch only ===\n",
        "    if last_all_labels is not None and last_all_preds is not None:\n",
        "        cm = confusion_matrix(last_all_labels, last_all_preds, labels=[0.0, 1.0])\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(5, 5))\n",
        "        disp.plot(ax=ax, values_format=\"d\")\n",
        "        ax.set_title(f\"Confusion Matrix - Last Epoch (Epoch {epochs})\")\n",
        "\n",
        "        cm_path = os.path.join(save_dir, \"confusion_matrix_last_epoch.png\")\n",
        "        fig.savefig(cm_path, bbox_inches=\"tight\")\n",
        "        plt.close(fig)\n",
        "        print(f\"Saved confusion matrix for last epoch to {cm_path}\")\n",
        "    else:\n",
        "        print(\"Warning: No labels/preds collected; confusion matrix not generated.\")\n",
        "\n",
        "    # Save embeddings\n",
        "    emb_path = os.path.join(save_dir, \"embedding_dict.pt\")\n",
        "    print(f\"Saving {len(embedding_dict)} embeddings to {emb_path}...\")\n",
        "    torch.save(embedding_dict, emb_path)\n",
        "    print(\"Done saving embeddings.\")\n",
        "\n",
        "    # Plotting epoch-level loss, accuracy, F1, precision, recall\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # --- Loss & Accuracy ---\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(epochs_range, epoch_losses, marker='o', linestyle='-', label='Train Loss')\n",
        "    plt.plot(epochs_range, val_losses, marker='x', linestyle='-', label='Val Loss')\n",
        "    plt.plot(epochs_range, epoch_accuracies, marker='s', linestyle='--', label='Train Accuracy')\n",
        "    plt.plot(epochs_range, val_accuracies, marker='d', linestyle='--', label='Val Accuracy')\n",
        "    plt.title('Training & Validation Loss & Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Value')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # --- F1, Precision, Recall ---\n",
        "    plt.subplot(2, 1, 2)\n",
        "    # F1\n",
        "    plt.plot(epochs_range, epoch_f1s, marker='^', linestyle='-', label='Train F1')\n",
        "    plt.plot(epochs_range, val_f1s, marker='v', linestyle='-', label='Val F1')\n",
        "    # Recall\n",
        "    plt.plot(epochs_range, epoch_recalls, marker='o', linestyle='-', label='Train Recall')\n",
        "    plt.plot(epochs_range, val_recalls, marker='o', linestyle='--', label='Val Recall')\n",
        "    # Precision\n",
        "    plt.plot(epochs_range, epoch_precisions, marker='s', linestyle='-', label='Train Precision')\n",
        "    plt.plot(epochs_range, val_precisions, marker='s', linestyle='--', label='Val Precision')\n",
        "\n",
        "    plt.title('Training & Validation F1 / Precision / Recall')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Score')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    loss_curve_path = os.path.join(save_dir, \"loss_acc_pr_rc_f1_curve.png\")\n",
        "    plt.savefig(loss_curve_path)\n",
        "    plt.close()\n",
        "    print(f\"Loss, accuracy, precision, recall, F1 curves saved to {loss_curve_path}\")\n",
        "\n",
        "    # === Test Evaluation ===\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(f\"TEST EVALUATION (Threshold={best_thresh:.2f})\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_all_preds = []\n",
        "    test_all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "            input_ids1 = batch['input_ids1'].to(device)\n",
        "            attention_mask1 = batch['attention_mask1'].to(device)\n",
        "            input_ids2 = batch['input_ids2'].to(device)\n",
        "            attention_mask2 = batch['attention_mask2'].to(device)\n",
        "            labels01 = batch['label'].to(device).float()\n",
        "            targets = 2 * labels01 - 1.0\n",
        "\n",
        "            embeddings1, embeddings2 = model(input_ids1, attention_mask1, input_ids2, attention_mask2)\n",
        "            loss = criterion(embeddings1, embeddings2, targets)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            cos_sim = F.cosine_similarity(embeddings1, embeddings2)\n",
        "            preds = (cos_sim >= best_thresh).float()\n",
        "\n",
        "            test_all_preds.extend(preds.cpu().numpy())\n",
        "            test_all_labels.extend(labels01.cpu().numpy())\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    test_acc = (np.array(test_all_preds) == np.array(test_all_labels)).mean()\n",
        "    test_f1 = f1_score(test_all_labels, test_all_preds, zero_division=0)\n",
        "    test_rec = recall_score(test_all_labels, test_all_preds, zero_division=0)\n",
        "    test_prec = precision_score(test_all_labels, test_all_preds, zero_division=0)\n",
        "\n",
        "    print(f\"Test  | Loss: {avg_test_loss:.4f} | Acc: {test_acc:.4f} | F1: {test_f1:.4f} | Rec: {test_rec:.4f} | Prec: {test_prec:.4f}\")\n",
        "\n",
        "    # Test Confusion Matrix\n",
        "    cm_test = confusion_matrix(test_all_labels, test_all_preds, labels=[0.0, 1.0])\n",
        "    print(\"\\nTest Confusion Matrix:\")\n",
        "    print(cm_test)\n",
        "\n",
        "    # Plot Test Confusion Matrix\n",
        "    disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=[0, 1])\n",
        "    fig_test, ax_test = plt.subplots(figsize=(5, 5))\n",
        "    disp_test.plot(ax=ax_test, values_format=\"d\", cmap='Blues')\n",
        "    ax_test.set_title(f\"Test Confusion Matrix (Threshold={best_thresh:.2f})\")\n",
        "\n",
        "    cm_test_path = os.path.join(save_dir, \"confusion_matrix_test.png\")\n",
        "    fig_test.savefig(cm_test_path, bbox_inches=\"tight\")\n",
        "    plt.close(fig_test)\n",
        "    print(f\"Saved test confusion matrix to {cm_test_path}\")\n",
        "\n",
        "    # Save Test Results\n",
        "    test_results_path = os.path.join(save_dir, \"test_results.txt\")\n",
        "    with open(test_results_path, \"w\") as f:\n",
        "        f.write(f\"Model Name: {model_name}\\n\")\n",
        "        f.write(f\"Test Evaluation (Threshold={best_thresh:.2f})\\n\")\n",
        "        f.write(f\"Loss: {avg_test_loss:.4f}\\n\")\n",
        "        f.write(f\"Accuracy: {test_acc:.4f}\\n\")\n",
        "        f.write(f\"F1 Score: {test_f1:.4f}\\n\")\n",
        "        f.write(f\"Recall: {test_rec:.4f}\\n\")\n",
        "        f.write(f\"Precision: {test_prec:.4f}\\n\")\n",
        "        f.write(\"\\nConfusion Matrix:\\n\")\n",
        "        f.write(str(cm_test))\n",
        "    print(f\"Test results saved to {test_results_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5d65309",
      "metadata": {
        "id": "f5d65309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "1c3b480c-b5fc-4517-ab8e-da81e70b59b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV path: /content/drive/.shortcut-targets-by-id/1AX1-1KC_cgwCqo-A4ecfxoHQWVfm-yV1/CS588/datasets/eclipse/tokenized_pairs_train_codebert-base_50000.csv\n",
            "Using device: cuda\n",
            "Loading dataset from /content/drive/.shortcut-targets-by-id/1AX1-1KC_cgwCqo-A4ecfxoHQWVfm-yV1/CS588/datasets/eclipse/tokenized_pairs_train_codebert-base_50000.csv...\n",
            "Dataset size: 50000\n",
            "Train size: 30000 | Validation size: 10000 | Test size: 10000\n",
            "Train batches: 15000 | Val batches: 5000 | Test batches: 5000\n",
            "Initializing SiameseBERT with microsoft/codebert-base...\n",
            "Checkpoints and figures will be saved under: checkpoints/eclipse/2025-12-25_08-47-55\n",
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 126/15000 [00:11<22:17, 11.12it/s, loss=0.2339, acc=0.500, f1=0.667]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1983069146.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# You can change batch_size, epochs, lr here if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{model_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset not found at {csv_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3635469340.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(csv_path, model_name, batch_size, epochs, lr, dataset_name)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# ---- Accuracy computation ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcos_sim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# {0,1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "baseline = \"codebert-base\"\n",
        "\n",
        "if baseline == \"codebert-base\":\n",
        "  model_name = \"microsoft/codebert-base\"\n",
        "elif baseline == \"bert-base-uncased\":\n",
        "  model_name = \"bert-base-uncased\"\n",
        "elif baseline == \"roberta-base\":\n",
        "  model_name = \"roberta-base\"\n",
        "\n",
        "# Adjust paths according to your project structure\n",
        "relative_path = \"eclipse\"\n",
        "dataset_dir = f\"datasets/{relative_path}/\"\n",
        "cur_dir = os.getcwd()\n",
        "csv_path = os.path.join(cur_dir, dataset_dir, f\"tokenized_pairs_train_{baseline}_50000.csv\")\n",
        "\n",
        "print(\"CSV path:\", csv_path)\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    # You can change batch_size, epochs, lr here if needed\n",
        "    train(csv_path, batch_size=2,epochs=5, dataset_name=relative_path, model_name=f\"{model_name}\")\n",
        "else:\n",
        "    print(f\"Dataset not found at {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cEMVWZPMEWOJ",
      "metadata": {
        "id": "cEMVWZPMEWOJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "embedding_dict_path = \"/content/drive/MyDrive/CS588/checkpoints/2025-12-09_17-22-30/embedding_dict.pt\"\n",
        "\n",
        "if os.path.exists(embedding_dict_path):\n",
        "    print(f\"Loading embedding dictionary from {embedding_dict_path}...\")\n",
        "    try:\n",
        "        embedding_dict = torch.load(embedding_dict_path)\n",
        "        print(f\"Embedding dictionary loaded successfully.\")\n",
        "        print(f\"Total number of embeddings: {len(embedding_dict)}\")\n",
        "\n",
        "        if len(embedding_dict) > 0:\n",
        "            print(\"\\n--- First 5 Embedding Keys and Shapes ---\")\n",
        "            for i, (key, embedding) in enumerate(embedding_dict.items()):\n",
        "                if i >= 5: # Only print first 5 for brevity\n",
        "                    break\n",
        "                if hasattr(embedding, 'shape'):\n",
        "                    print(f\"Key: {key}, Embedding Shape: {embedding.shape}\")\n",
        "                elif isinstance(embedding, torch.Tensor):\n",
        "                    print(f\"Key: {key}, Embedding Shape: {embedding.shape}\")\n",
        "                else:\n",
        "                    print(f\"Key: {key}, Could not determine shape.\")\n",
        "            if len(embedding_dict) > 5:\n",
        "                print(f\"... and {len(embedding_dict) - 5} more entries.\")\n",
        "        else:\n",
        "            print(\"The embedding dictionary is empty.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading embedding_dict.pt: {e}\")\n",
        "        print(\"The file might be corrupted or incomplete due to the interruption.\")\n",
        "else:\n",
        "    print(f\"Embedding dictionary file not found at {embedding_dict_path}.\")\n",
        "    print(\"This might be because the training was interrupted before the dictionary was saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aLusoFAetdsX",
      "metadata": {
        "id": "aLusoFAetdsX"
      },
      "source": [
        "**This part for sbertgcn**\n",
        "\n",
        "Ours!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UhxZlQI8Lbmz",
      "metadata": {
        "id": "UhxZlQI8Lbmz"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SBERT + GCN Training Script (Colab-friendly)\n",
        "# - TQDM shows per-batch: Loss, F1, Acc\n",
        "# - At the end: epoch-level plots for Loss/F1/Acc/Precision/Recall\n",
        "# - Saves test confusion matrix\n",
        "# ============================================================\n",
        "\n",
        "!pip install torch-geometric  # Uncomment if you really need PyG for your gnn2.py\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "from scipy import sparse\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Local Imports\n",
        "from dataset import TokenizedDataset\n",
        "from sbert import SiameseBERT\n",
        "from gnn3 import SBERTGCN, normalize_edge_index\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Device\n",
        "# ---------------------------\n",
        "def _device() -> torch.device:\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Graph loading\n",
        "# ---------------------------\n",
        "def _load_graph(dataset_dir: str, device: torch.device):\n",
        "    adj = sparse.load_npz(os.path.join(dataset_dir, \"graph_adj.npz\")).tocsr()\n",
        "    node_ids = np.load(os.path.join(dataset_dir, \"graph_adj_node_ids.npy\"))\n",
        "    coo = adj.tocoo()\n",
        "\n",
        "    edge_index = torch.from_numpy(\n",
        "        np.vstack([coo.row, coo.col]).astype(np.int64)\n",
        "    ).to(device)\n",
        "\n",
        "    # normalize_edge_index is assumed to return (edge_index, edge_weight)\n",
        "    edge_index, edge_weight = normalize_edge_index(edge_index, len(node_ids))\n",
        "    edge_index = edge_index.to(device)\n",
        "    edge_weight = edge_weight.to(device)\n",
        "\n",
        "    return (edge_index, edge_weight), node_ids\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Batch pair -> graph indices\n",
        "# ---------------------------\n",
        "def _pairs_to_indices(batch, id_to_idx, device):\n",
        "    idx1, idx2, labs = [], [], []\n",
        "\n",
        "    for a, b, y in zip(batch[\"issue_id1\"], batch[\"issue_id2\"], batch[\"label\"]):\n",
        "        a_id, b_id = int(a), int(b)\n",
        "        if a_id in id_to_idx and b_id in id_to_idx:\n",
        "            idx1.append(id_to_idx[a_id])\n",
        "            idx2.append(id_to_idx[b_id])\n",
        "            labs.append(float(y))\n",
        "\n",
        "    if not idx1:\n",
        "        return None, None, None\n",
        "\n",
        "    return (\n",
        "        torch.tensor(idx1, device=device),\n",
        "        torch.tensor(idx2, device=device),\n",
        "        torch.tensor(labs, device=device),\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Threshold selection on VAL\n",
        "# ---------------------------\n",
        "def _get_best_threshold(sims: np.ndarray, labs: np.ndarray) -> float:\n",
        "    thresholds = np.linspace(0.1, 0.9, 17)\n",
        "    best_f1, best_th = 0.0, 0.5\n",
        "    for th in thresholds:\n",
        "        preds = (sims >= th).astype(int)\n",
        "        f1 = f1_score(labs, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_th = f1, th\n",
        "    return float(best_th)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Epoch runner\n",
        "# - tqdm: per-batch Loss/F1/Acc only\n",
        "# - returns epoch metrics: loss/acc/f1/precision/recall + sims/labs\n",
        "# ---------------------------\n",
        "def _run_epoch(\n",
        "    loader,\n",
        "    node_emb,\n",
        "    model,\n",
        "    edge_index,\n",
        "    edge_weight,\n",
        "    id_to_idx,\n",
        "    device,\n",
        "    criterion,\n",
        "    optimizer=None,\n",
        "    thresh=0.5,\n",
        "    desc=\"Run\",\n",
        "):\n",
        "    is_train = optimizer is not None\n",
        "    model.train(is_train)\n",
        "    node_emb.train(is_train)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    seen_batches = 0\n",
        "    all_sims, all_labs = [], []\n",
        "\n",
        "    pbar = tqdm(loader, desc=desc, leave=False)\n",
        "\n",
        "    for batch in pbar:\n",
        "        idx, idy, labs_batch = _pairs_to_indices(batch, id_to_idx, device)\n",
        "        if idx is None:\n",
        "            continue\n",
        "\n",
        "        ids1 = batch[\"input_ids1\"].to(device)\n",
        "        m1 = batch[\"attention_mask1\"].to(device)\n",
        "        ids2 = batch[\"input_ids2\"].to(device)\n",
        "        m2 = batch[\"attention_mask2\"].to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            out1, out2 = model(\n",
        "                node_emb,\n",
        "                idx,\n",
        "                idy,\n",
        "                ids1,\n",
        "                m1,\n",
        "                ids2,\n",
        "                m2,\n",
        "                edge_index,\n",
        "                edge_weight,\n",
        "            )\n",
        "            out1 = F.normalize(out1, dim=1)\n",
        "            out2 = F.normalize(out2, dim=1)\n",
        "\n",
        "            loss = criterion(out1, out2, (2 * labs_batch - 1.0))\n",
        "\n",
        "            if is_train:\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        sims = F.cosine_similarity(out1, out2).detach().cpu().numpy()\n",
        "        labs = labs_batch.detach().cpu().numpy().astype(int)\n",
        "        preds = (sims >= thresh).astype(int)\n",
        "\n",
        "        b_loss = float(loss.item())\n",
        "        b_f1 = f1_score(labs, preds, zero_division=0)\n",
        "        b_acc = float((labs == preds).mean())\n",
        "\n",
        "        pbar.set_postfix({\"L\": f\"{b_loss:.3f}\", \"F1\": f\"{b_f1:.3f}\", \"Acc\": f\"{b_acc:.3f}\"})\n",
        "\n",
        "        total_loss += b_loss\n",
        "        seen_batches += 1\n",
        "        all_sims.extend(sims.tolist())\n",
        "        all_labs.extend(labs.tolist())\n",
        "\n",
        "    all_sims = np.asarray(all_sims, dtype=np.float32)\n",
        "    all_labs = np.asarray(all_labs, dtype=np.int32)\n",
        "\n",
        "    if all_labs.size == 0:\n",
        "        return {\n",
        "            \"loss\": 0.0,\n",
        "            \"acc\": 0.0,\n",
        "            \"f1\": 0.0,\n",
        "            \"precision\": 0.0,\n",
        "            \"recall\": 0.0,\n",
        "            \"sims\": all_sims,\n",
        "            \"labs\": all_labs,\n",
        "        }\n",
        "\n",
        "    preds_all = (all_sims >= thresh).astype(int)\n",
        "\n",
        "    return {\n",
        "        \"loss\": total_loss / max(1, seen_batches),\n",
        "        \"acc\": float((preds_all == all_labs).mean()),\n",
        "        \"f1\": f1_score(all_labs, preds_all, zero_division=0),\n",
        "        \"precision\": precision_score(all_labs, preds_all, zero_division=0),\n",
        "        \"recall\": recall_score(all_labs, preds_all, zero_division=0),\n",
        "        \"sims\": all_sims,\n",
        "        \"labs\": all_labs,\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Plot epoch-level metrics (end only)\n",
        "# ---------------------------\n",
        "def _save_epoch_plots(epoch_hist, ckpt_dir, dataset_name=\"\"):\n",
        "    metrics = [\"loss\", \"f1\", \"acc\", \"precision\", \"recall\"]\n",
        "    epochs = np.arange(1, len(epoch_hist[\"train\"][\"loss\"]) + 1)\n",
        "\n",
        "    for m in metrics:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(epochs, epoch_hist[\"train\"][m], label=f\"Train {m.upper()}\")\n",
        "        plt.plot(epochs, epoch_hist[\"val\"][m], label=f\"Val {m.upper()}\")\n",
        "        plt.title(f\"Epoch-level {m.upper()} - {dataset_name}\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(m.upper())\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(ckpt_dir, f\"epoch_{m}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Confusion matrix plot (end only)\n",
        "# ---------------------------\n",
        "def _save_confusion_matrix(ts_m, ckpt_dir, test_th=0.5):\n",
        "    preds = (ts_m[\"sims\"] >= test_th).astype(int)\n",
        "    cm = confusion_matrix(ts_m[\"labs\"], preds)\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(cm)\n",
        "    plt.title(f\"Test Confusion Matrix (th={test_th:.2f})\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.xticks([0, 1], [\"Unique\", \"Duplicate\"])\n",
        "    plt.yticks([0, 1], [\"Unique\", \"Duplicate\"])\n",
        "\n",
        "    for (i, j), v in np.ndenumerate(cm):\n",
        "        plt.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(ckpt_dir, \"test_confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Main training pipeline\n",
        "# ---------------------------\n",
        "def train_bertgnn(csv_path, dataset_dir, batch_size=16, epochs=5, lr=2e-5):\n",
        "    device = _device()\n",
        "    dataset_name = os.path.basename(os.path.normpath(dataset_dir))\n",
        "    run_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    ckpt_dir = os.path.join(\"checkpoints\", dataset_name, f\"run_{run_ts}\")\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    print(f\"Dataset: {dataset_name} | Artifacts: {ckpt_dir}\")\n",
        "\n",
        "    (edge_index, edge_weight), node_ids = _load_graph(dataset_dir, device)\n",
        "    id_to_idx = {int(nid): i for i, nid in enumerate(node_ids)}\n",
        "\n",
        "    dataset = TokenizedDataset(csv_path)\n",
        "    n = len(dataset)\n",
        "\n",
        "    n_train = int(0.6 * n)\n",
        "    n_val = int(0.2 * n)\n",
        "    n_test = n - n_train - n_val\n",
        "\n",
        "    train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test])\n",
        "\n",
        "    loaders = {\n",
        "        \"train\": DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
        "        \"val\": DataLoader(val_ds, batch_size=batch_size, shuffle=False),\n",
        "        \"test\": DataLoader(test_ds, batch_size=batch_size, shuffle=False),\n",
        "    }\n",
        "\n",
        "    node_emb = nn.Embedding(len(node_ids), 128).to(device)\n",
        "    model = SBERTGCN(SiameseBERT().to(device), len(node_ids), 128, 128, l=0.5).to(device)\n",
        "\n",
        "    optimizer = AdamW(list(model.parameters()) + list(node_emb.parameters()), lr=lr)\n",
        "    criterion = nn.CosineEmbeddingLoss(margin=0.5)\n",
        "\n",
        "    best_val_f1 = 0.0\n",
        "    locked_th = 0.5\n",
        "\n",
        "    epoch_hist = {\n",
        "        \"train\": {k: [] for k in [\"loss\", \"f1\", \"acc\", \"precision\", \"recall\"]},\n",
        "        \"val\": {k: [] for k in [\"loss\", \"f1\", \"acc\", \"precision\", \"recall\"]},\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        tr_m = _run_epoch(\n",
        "            loaders[\"train\"],\n",
        "            node_emb,\n",
        "            model,\n",
        "            edge_index,\n",
        "            edge_weight,\n",
        "            id_to_idx,\n",
        "            device,\n",
        "            criterion,\n",
        "            optimizer=optimizer,\n",
        "            thresh=locked_th,\n",
        "            desc=f\"Ep {epoch+1} Train\",\n",
        "        )\n",
        "\n",
        "        val_m = _run_epoch(\n",
        "            loaders[\"val\"],\n",
        "            node_emb,\n",
        "            model,\n",
        "            edge_index,\n",
        "            edge_weight,\n",
        "            id_to_idx,\n",
        "            device,\n",
        "            criterion,\n",
        "            optimizer=None,\n",
        "            thresh=locked_th,\n",
        "            desc=f\"Ep {epoch+1} Val\",\n",
        "        )\n",
        "\n",
        "        for k in [\"loss\", \"f1\", \"acc\", \"precision\", \"recall\"]:\n",
        "            epoch_hist[\"train\"][k].append(tr_m[k])\n",
        "            epoch_hist[\"val\"][k].append(val_m[k])\n",
        "\n",
        "        epoch_best_th = _get_best_threshold(val_m[\"sims\"], val_m[\"labs\"])\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}/{epochs} | \"\n",
        "            f\"Val F1: {val_m['f1']:.4f} | Val Prec: {val_m['precision']:.4f} | Val Rec: {val_m['recall']:.4f} | \"\n",
        "            f\"Next Th: {epoch_best_th:.2f}\"\n",
        "        )\n",
        "\n",
        "        if val_m[\"f1\"] > best_val_f1:\n",
        "            best_val_f1 = val_m[\"f1\"]\n",
        "            locked_th = epoch_best_th\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"emb\": node_emb.state_dict(), \"thresh\": locked_th},\n",
        "                os.path.join(ckpt_dir, \"best_model.pth\"),\n",
        "            )\n",
        "\n",
        "    # -----------------------\n",
        "    # Final test (best ckpt)\n",
        "    # -----------------------\n",
        "    print(\"\\n\" + \"=\" * 20 + \" FINAL TEST \" + \"=\" * 20)\n",
        "    best_ckpt = torch.load(os.path.join(ckpt_dir, \"best_model.pth\"), weights_only=False)\n",
        "    model.load_state_dict(best_ckpt[\"model\"])\n",
        "    node_emb.load_state_dict(best_ckpt[\"emb\"])\n",
        "    test_th = float(best_ckpt[\"thresh\"])\n",
        "\n",
        "    ts_m = _run_epoch(\n",
        "        loaders[\"test\"],\n",
        "        node_emb,\n",
        "        model,\n",
        "        edge_index,\n",
        "        edge_weight,\n",
        "        id_to_idx,\n",
        "        device,\n",
        "        criterion,\n",
        "        optimizer=None,\n",
        "        thresh=test_th,\n",
        "        desc=\"Test Set\",\n",
        "    )\n",
        "\n",
        "    _save_epoch_plots(epoch_hist, ckpt_dir, dataset_name=dataset_name)\n",
        "    _save_confusion_matrix(ts_m, ckpt_dir, test_th=test_th)\n",
        "\n",
        "    print(\n",
        "        f\"Final Test | F1: {ts_m['f1']:.4f} | Prec: {ts_m['precision']:.4f} | \"\n",
        "        f\"Rec: {ts_m['recall']:.4f} | Th: {test_th:.2f}\"\n",
        "    )\n",
        "    print(f\"Saved plots in: {ckpt_dir}\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Entry\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    D_DIR = \"datasets/eclipse\"\n",
        "    CSV = os.path.join(D_DIR, \"tokenized_pairs_train_bert-base-uncased_50000.csv\")\n",
        "    train_bertgnn(CSV, D_DIR, epochs=10, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ya__3JCvzq7O",
      "metadata": {
        "id": "ya__3JCvzq7O"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aLoPiHxQ3wC_",
      "metadata": {
        "id": "aLoPiHxQ3wC_"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}